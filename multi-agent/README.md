# 论文

## Multi-Agent Multi-View Collaborative Perception Based on Semi-Supervised Online Evolutive Learning

### 年份

2022

### 背景

很多实时场景（如自动驾驶、智慧工厂、智能安防）都需要多个传感器（摄像头、雷达等）同时感知环境，并在边缘侧（设备本地而非云端）完成快速识别和决策

每个设备（智能体、agent）之间相互协作，利用不同视角互相补充，提升整体准确性

### 核心思想

MACP（Multi-view Agent’s Collaborative Perception）

1. 多视角多智能体

* 一个场景由多个智能体（摄像头、雷达等）从不同角度观测，同一时刻可以得到多种“视角信息”。
* 每个视角对应一个识别模型。

2. 自监督初始化

* 刚开始，给每个视角的模型做自监督预训练。
* 这样每个模型在一开始就有能力提取出与自己视角相关、且和其他视角有一定“互补性”的特征。

3. 半监督一致性学习

* 对于新采集到的未标注数据：

  * 各个视角模型先独立做预测；
  * 把各个模型的预测结果**融合**，生成高置信度的伪标签；
  * 用这些伪标签做一致性正则化：即要求相同输入在数据增强或扰动下，各模型输出尽量一致。

* 这样就能充分利用未标注数据，不断优化模型。

4. 视角独立性保持

* 多模型在协同训练时容易变得相似，失去互补性。
* 为了防止这一点，MACP在训练中加入了对关键参数的限制，鼓励每个模型保持自己的“辨别独立性”，从而发挥多视角互补的优势。


### 实验验证

论文做了多种实验来验证 MACP：

1. 对比方法：
   与经典的单模型 SSL（如 Mean Teacher、FixMatch）以及已有的多模型 SSL 方法对比。

2. 指标：

   * 收敛速度（训练多少轮就达到较高准确率）
   * 最终准确率（泛化性能）

3. MACP 在多个数据集上表现都更好，证明了：

     * 多视角信息确实带来了判别能力提升；
     * 视角独立性保持机制有效防止了模型同质化。
